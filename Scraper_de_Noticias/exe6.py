"""ğŸ”´ Projeto 2 â€“ Scraper de NotÃ­cias com ExportaÃ§Ã£o e Consulta
ğŸ’¡ Objetivo:
Criar um robÃ´ que busca notÃ­cias automaticamente de um site e permite consultar, salvar e atualizar os dados de forma estruturada.

ğŸ“¦ Desafio Completo:
1. Funcionalidades principais:
Acessar sites como G1, Terra, CNN Brasil

Usar requests + BeautifulSoup para extrair:

TÃ­tulo da notÃ­cia

Link

Data de publicaÃ§Ã£o (se possÃ­vel)

Armazenar os dados em .csv, .json ou banco SQLite

Permitir pesquisa de notÃ­cias por palavras-chave

2. Funcionalidades extras:
Agendar execuÃ§Ã£o com schedule ou cron (scraping automÃ¡tico)

Criar uma interface bÃ¡sica com tkinter ou streamlit

Adicionar filtro de data ou categoria

Criar uma API simples com Flask para servir os dados via JSON

ğŸ¯ Resultado:
Um projeto completo de extraÃ§Ã£o de dados da web + organizaÃ§Ã£o + consulta, ideal para treinar web scraping, estruturaÃ§Ã£o de dados e interface.

ğŸ“ OrganizaÃ§Ã£o recomendada do repositÃ³rio GitHub:
/src â†’ scripts principais

/data â†’ arquivos .csv ou .json

/notebooks â†’ se usar Jupyter para anÃ¡lise

README.md explicando o projeto, dependÃªncias e como executar

requirements.txt com bibliotecas usadas
"""